{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a name for the png image to be saved: HU25defaultparams\n",
      "loading data...\n",
      "optimizing parameter values...\n",
      "visualizing optimal weights...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This piece of software is bound by The MIT License (MIT)\n",
    "# Copyright (c) 2013 Siddharth Agrawal\n",
    "# Code written by : Siddharth Agrawal\n",
    "# Email ID : siddharth.950@gmail.com\n",
    "\n",
    "import numpy\n",
    "import math\n",
    "import time\n",
    "import scipy.io\n",
    "import scipy.optimize\n",
    "import matplotlib.pyplot\n",
    "\n",
    "###########################################################################################\n",
    "\"\"\" The Sparse Autoencoder class \"\"\"\n",
    "\n",
    "class SparseAutoencoder(object):\n",
    "\n",
    "    #######################################################################################\n",
    "    \"\"\" Initialization of Autoencoder object \"\"\"\n",
    "\n",
    "    def __init__(self, visible_size, hidden_size, rho, lamda, beta):\n",
    "    \n",
    "        \"\"\" Initialize parameters of the Autoencoder object \"\"\"\n",
    "    \n",
    "        self.visible_size = visible_size    # number of input units\n",
    "        self.hidden_size = hidden_size      # number of hidden units\n",
    "        self.rho = rho                      # desired average activation of hidden units\n",
    "        self.lamda = lamda                  # weight decay parameter\n",
    "        self.beta = beta                    # weight of sparsity penalty term\n",
    "        \n",
    "        \"\"\" Set limits for accessing 'theta' values \"\"\"\n",
    "        \n",
    "        self.limit0 = 0\n",
    "        self.limit1 = hidden_size * visible_size\n",
    "        self.limit2 = 2 * hidden_size * visible_size\n",
    "        self.limit3 = 2 * hidden_size * visible_size + hidden_size\n",
    "        self.limit4 = 2 * hidden_size * visible_size + hidden_size + visible_size\n",
    "        \n",
    "        \"\"\" Initialize Neural Network weights randomly\n",
    "            W1, W2 values are chosen in the range [-r, r] \"\"\"\n",
    "        \n",
    "        r = math.sqrt(6) / math.sqrt(visible_size + hidden_size + 1)\n",
    "        \n",
    "        rand = numpy.random.RandomState(int(time.time()))\n",
    "        \n",
    "        W1 = numpy.asarray(rand.uniform(low = -r, high = r, size = (hidden_size, visible_size)))\n",
    "        W2 = numpy.asarray(rand.uniform(low = -r, high = r, size = (visible_size, hidden_size)))\n",
    "        \n",
    "        \"\"\" Bias values are initialized to zero \"\"\"\n",
    "        \n",
    "        b1 = numpy.zeros((hidden_size, 1))\n",
    "        b2 = numpy.zeros((visible_size, 1))\n",
    "\n",
    "        \"\"\" Create 'theta' by unrolling W1, W2, b1, b2 \"\"\"\n",
    "\n",
    "        self.theta = numpy.concatenate((W1.flatten(), W2.flatten(),\n",
    "                                        b1.flatten(), b2.flatten()))\n",
    "\n",
    "    #######################################################################################\n",
    "    \"\"\" Returns elementwise sigmoid output of input array \"\"\"\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "    \n",
    "        return (1 / (1 + numpy.exp(-x)))\n",
    "\n",
    "    #######################################################################################\n",
    "    \"\"\" Returns the cost of the Autoencoder and gradient at a particular 'theta' \"\"\"\n",
    "        \n",
    "    def sparseAutoencoderCost(self, theta, input):\n",
    "        \n",
    "        \"\"\" Extract weights and biases from 'theta' input \"\"\"\n",
    "        \n",
    "        W1 = theta[self.limit0 : self.limit1].reshape(self.hidden_size, self.visible_size)\n",
    "        W2 = theta[self.limit1 : self.limit2].reshape(self.visible_size, self.hidden_size)\n",
    "        b1 = theta[self.limit2 : self.limit3].reshape(self.hidden_size, 1)\n",
    "        b2 = theta[self.limit3 : self.limit4].reshape(self.visible_size, 1)\n",
    "        \n",
    "        \"\"\" Compute output layers by performing a feedforward pass\n",
    "            Computation is done for all the training inputs simultaneously \"\"\"\n",
    "        \n",
    "        hidden_layer = self.sigmoid(numpy.dot(W1, input) + b1)\n",
    "        output_layer = self.sigmoid(numpy.dot(W2, hidden_layer) + b2)\n",
    "        \n",
    "        \"\"\" Estimate the average activation value of the hidden layers \"\"\"\n",
    "        \n",
    "        rho_cap = numpy.sum(hidden_layer, axis = 1) / input.shape[1]\n",
    "        \n",
    "        \"\"\" Compute intermediate difference values using Backpropagation algorithm \"\"\"\n",
    "        \n",
    "        diff = output_layer - input\n",
    "        \n",
    "        sum_of_squares_error = 0.5 * numpy.sum(numpy.multiply(diff, diff)) / input.shape[1]\n",
    "        weight_decay         = 0.5 * self.lamda * (numpy.sum(numpy.multiply(W1, W1)) +\n",
    "                                                   numpy.sum(numpy.multiply(W2, W2)))\n",
    "        KL_divergence        = self.beta * numpy.sum(self.rho * numpy.log(self.rho / rho_cap) +\n",
    "                                                    (1 - self.rho) * numpy.log((1 - self.rho) / (1 - rho_cap)))\n",
    "        cost                 = sum_of_squares_error + weight_decay + KL_divergence\n",
    "        \n",
    "        KL_div_grad = self.beta * (-(self.rho / rho_cap) + ((1 - self.rho) / (1 - rho_cap)))\n",
    "        \n",
    "        del_out = numpy.multiply(diff, numpy.multiply(output_layer, 1 - output_layer))\n",
    "        del_hid = numpy.multiply(numpy.dot(numpy.transpose(W2), del_out) + numpy.transpose(numpy.matrix(KL_div_grad)), \n",
    "                                 numpy.multiply(hidden_layer, 1 - hidden_layer))\n",
    "        \n",
    "        \"\"\" Compute the gradient values by averaging partial derivatives\n",
    "            Partial derivatives are averaged over all training examples \"\"\"\n",
    "            \n",
    "        W1_grad = numpy.dot(del_hid, numpy.transpose(input))\n",
    "        W2_grad = numpy.dot(del_out, numpy.transpose(hidden_layer))\n",
    "        b1_grad = numpy.sum(del_hid, axis = 1)\n",
    "        b2_grad = numpy.sum(del_out, axis = 1)\n",
    "            \n",
    "        W1_grad = W1_grad / input.shape[1] + self.lamda * W1\n",
    "        W2_grad = W2_grad / input.shape[1] + self.lamda * W2\n",
    "        b1_grad = b1_grad / input.shape[1]\n",
    "        b2_grad = b2_grad / input.shape[1]\n",
    "        \n",
    "        \"\"\" Transform numpy matrices into arrays \"\"\"\n",
    "        \n",
    "        W1_grad = numpy.array(W1_grad)\n",
    "        W2_grad = numpy.array(W2_grad)\n",
    "        b1_grad = numpy.array(b1_grad)\n",
    "        b2_grad = numpy.array(b2_grad)\n",
    "        \n",
    "        \"\"\" Unroll the gradient values and return as 'theta' gradient \"\"\"\n",
    "        \n",
    "        theta_grad = numpy.concatenate((W1_grad.flatten(), W2_grad.flatten(),\n",
    "                                        b1_grad.flatten(), b2_grad.flatten()))\n",
    "                                        \n",
    "        return [cost, theta_grad]\n",
    "\n",
    "###########################################################################################\n",
    "\"\"\" Normalize the dataset provided as input \"\"\"\n",
    "\n",
    "def normalizeDataset(dataset):\n",
    "\n",
    "    \"\"\" Remove mean of dataset \"\"\"\n",
    "\n",
    "    dataset = dataset - numpy.mean(dataset)\n",
    "    \n",
    "    \"\"\" Truncate to +/-3 standard deviations and scale to -1 to 1 \"\"\"\n",
    "    \n",
    "    std_dev = 3 * numpy.std(dataset)\n",
    "    dataset = numpy.maximum(numpy.minimum(dataset, std_dev), -std_dev) / std_dev\n",
    "    \n",
    "    \"\"\" Rescale from [-1, 1] to [0.1, 0.9] \"\"\"\n",
    "    \n",
    "    dataset = (dataset + 1) * 0.4 + 0.1\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "###########################################################################################\n",
    "\"\"\" Randomly samples image patches, normalizes them and returns as dataset \"\"\"\n",
    "\n",
    "def loadDataset(num_patches, patch_side):\n",
    "\n",
    "    \"\"\" Load images into numpy array \"\"\"\n",
    "\n",
    "    images = scipy.io.loadmat('IMAGES.mat')\n",
    "    images = images['IMAGES']\n",
    "    \n",
    "    \"\"\" Initialize dataset as array of zeros \"\"\"\n",
    "    \n",
    "    dataset = numpy.zeros((patch_side*patch_side, num_patches))\n",
    "    \n",
    "    \"\"\" Initialize random numbers for random sampling of images\n",
    "        There are 10 images of size 512 X 512 \"\"\"\n",
    "    \n",
    "    rand = numpy.random.RandomState(int(time.time()))\n",
    "    image_indices = rand.randint(512 - patch_side, size = (num_patches, 2))\n",
    "    image_number  = rand.randint(10, size = num_patches)\n",
    "    \n",
    "    \"\"\" Sample 'num_patches' random image patches \"\"\"\n",
    "    \n",
    "    for i in range(num_patches):\n",
    "    \n",
    "        \"\"\" Initialize indices for patch extraction \"\"\"\n",
    "    \n",
    "        index1 = image_indices[i, 0]\n",
    "        index2 = image_indices[i, 1]\n",
    "        index3 = image_number[i]\n",
    "        \n",
    "        \"\"\" Extract patch and store it as a column \"\"\"\n",
    "        \n",
    "        patch = images[index1:index1+patch_side, index2:index2+patch_side, index3]\n",
    "        patch = patch.flatten()\n",
    "        dataset[:, i] = patch\n",
    "    \n",
    "    \"\"\" Normalize and return the dataset \"\"\"\n",
    "    \n",
    "    dataset = normalizeDataset(dataset)\n",
    "    return dataset\n",
    "\n",
    "###########################################################################################\n",
    "\"\"\" Visualizes the obtained optimal W1 values as images \"\"\"\n",
    "\n",
    "def visualizeW1(opt_W1, vis_patch_side, hid_patch_side, input_filename):\n",
    "\n",
    "    \"\"\" Add the weights as a matrix of images \"\"\"\n",
    "    \n",
    "    figure, axes = matplotlib.pyplot.subplots(nrows = hid_patch_side,\n",
    "                                              ncols = hid_patch_side)\n",
    "    index = 0\n",
    "    \n",
    "    #filename = '25hiddenunits'\n",
    "    #f = open(filename,\"w+\")\n",
    "                                              \n",
    "    for axis in axes.flat:\n",
    "    \n",
    "        \"\"\" Add row of weights as an image to the plot \"\"\"\n",
    "    \n",
    "        image = axis.imshow(opt_W1[index, :].reshape(vis_patch_side, vis_patch_side),\n",
    "                            cmap = matplotlib.pyplot.cm.gray, interpolation = 'nearest')\n",
    "        \n",
    "      #  f.write(\"%s\\n\" % opt_W1[index, :])\n",
    "        \n",
    "        axis.set_frame_on(False)\n",
    "        axis.set_axis_off()\n",
    "        index += 1\n",
    "        \n",
    "    \"\"\" Show the obtained plot \"\"\"  \n",
    "    \n",
    "    filename = input_filename + '.png'\n",
    "    \n",
    "    figure.savefig(filename, bbox_inches='tight')\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "###########################################################################################\n",
    "\"\"\" Loads data, trains the Autoencoder and visualizes the learned weights \"\"\"\n",
    "\n",
    "def executeSparseAutoencoder():\n",
    "\n",
    "    \"\"\" Define the parameters of the Autoencoder \"\"\"\n",
    "    \n",
    "    vis_patch_side = 8      # side length of sampled image patches\n",
    "    hid_patch_side = 5      # side length of representative image patches\n",
    "    rho            = 0.01   # desired average activation of hidden units\n",
    "    lamda          = 0.0001 # weight decay parameter\n",
    "    beta           = 3      # weight of sparsity penalty term\n",
    "    num_patches    = 10000  # number of training examples\n",
    "    max_iterations = 400    # number of optimization iterations\n",
    "\n",
    "    visible_size = vis_patch_side * vis_patch_side  # number of input units\n",
    "    hidden_size  = hid_patch_side * hid_patch_side  # number of hidden units\n",
    "    \n",
    "    \"\"\" Load randomly sampled image patches as dataset \"\"\"\n",
    "    \n",
    "    input_filename = input(\"Enter a name for the png image to be saved: \")\n",
    "    \n",
    "    print(\"loading data...\")\n",
    "    training_data = loadDataset(num_patches, vis_patch_side)\n",
    "    \n",
    "    \"\"\" Initialize the Autoencoder with the above parameters \"\"\"\n",
    "    \n",
    "    encoder = SparseAutoencoder(visible_size, hidden_size, rho, lamda, beta)\n",
    "    \n",
    "    \"\"\" Run the L-BFGS algorithm to get the optimal parameter values \"\"\"\n",
    "    \n",
    "    print(\"optimizing parameter values...\")\n",
    "    opt_solution  = scipy.optimize.minimize(encoder.sparseAutoencoderCost, encoder.theta, \n",
    "                                            args = (training_data,), method = 'L-BFGS-B', \n",
    "                                            jac = True, options = {'maxiter': max_iterations})\n",
    "    opt_theta     = opt_solution.x\n",
    "    opt_W1        = opt_theta[encoder.limit0 : encoder.limit1].reshape(hidden_size, visible_size)\n",
    "\n",
    "    \"\"\" Visualize the obtained optimal W1 weights \"\"\"\n",
    "\n",
    "    print(\"visualizing optimal weights...\")\n",
    "    visualizeW1(opt_W1, vis_patch_side, hid_patch_side, input_filename)\n",
    "\n",
    "executeSparseAutoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
